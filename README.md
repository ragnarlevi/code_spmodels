ReadMe
================

# code_spmodels

The code requires the package [tidyverse](https://www.tidyverse.org/) to
be installed: `install.packages("tidyverse")`.

To run the case study on a generate toy data set, please run
`toy_data_analysis.R`.

## Run the models

``` r
source("utils.R")  # gradients and helper functions
source("poisson.R")  # All Poisson models models
source("zip_mixed.R")  # Zip and mixed zip models
source("hurdle_mixed.R") # hurdle and mixed hurdle models
source("simulate_data.R")  # to gernerate data


#####################
# Test Poisson
#####################
# Poisson is purely L-BFGS-B
sim <- simulate_claims(50, 100, spatial_type = "graph", additive =  FALSE, area = 10, 
                           model_type = "poisson", mixing = "gamma", density = 0.4,  seed = 1)

out_poisson <- Poisson(sim$claims, sim$X, sim$locs, sim$years, sim$agg_claims, sim$A, additive = FALSE, model_type = "learn_graph", 
                       lambda = 0, 
                       exposure = sim$exposure, 
                       max_itr = 500)

out_poisson_mixed <- Poisson_mixed(claims = sim$claims, 
                           X = sim$X, 
                           locs = sim$locs, 
                           years = sim$years, 
                           agg_claims = sim$agg_claims,
                           A = sim$A,   # can be NA if A is learned
                           additive = FALSE, 
                           model_type = "learn_graph", 
                           lambda = 0,
                           exposure = sim$exposure,  
                           mixing_var = "gamma", 
                            Q_tol = 0,
                           nr_em = 60,
                           verbose = 0  # increase number for info
                           )
```

    ## [1] "Breaking because parameters have stopped changing"

``` r
# Louis method error, first few parameters
sqrt(diag(solve(out_poisson_mixed$Hessian-out_poisson_mixed$var_loglik)))[1:5]
```

    ##                   X11        X12        X13            
    ## 0.03127191 0.09569682 0.13410355 0.13721541 0.36369486

``` r
# Beta error
cat("\n# Beta Error\n")
```

    ## 
    ## # Beta Error

``` r
cat("Poisson model beta1 error:", sum(abs(out_poisson$beta1 - sim$beta1)), "\n")
```

    ## Poisson model beta1 error: 0.3760549

``` r
cat("Poisson mixed model beta1 error:", sum(abs(out_poisson_mixed$beta1 - sim$beta1)), "\n")
```

    ## Poisson mixed model beta1 error: 0.3562951

``` r
# Alpha error
cat("\n# Alpha Error\n")
```

    ## 
    ## # Alpha Error

``` r
cat("Poisson model a error:", sum(abs(out_poisson$a - sim$a)), "\n")
```

    ## Poisson model a error: 8.392337

``` r
cat("Poisson mixed model a error:", sum(abs(out_poisson_mixed$a - sim$a)), "\n")
```

    ## Poisson mixed model a error: 7.922855

``` r
# Beta_phi error
cat("\n# Beta_phi Error\n")
```

    ## 
    ## # Beta_phi Error

``` r
cat("Poisson mixed model beta phi error:", sum(abs(out_poisson_mixed$beta2 - sim$beta2)), "\n")
```

    ## Poisson mixed model beta phi error: 0.01698877

``` r
#####################
# Test Zip
#####################
source("zip_mixed.R")  # Zip and mixed zip models
zip_sim <- simulate_claims(50, 100, spatial_type = "graph", additive =  TRUE, area = 10, 
                           model_type = "zip", mixing = "ln", density = 0.4,  seed = 1)

# not mixed
out_zip <- zip(claims = zip_sim$claims, X1 = zip_sim$X, locs = zip_sim$locs, 
               years = zip_sim$years,  agg_claims = zip_sim$agg_claims, 
                 A = zip_sim$A, additive = TRUE, 
                model_type = "learn_graph", 
               exposure = zip_sim$exposure, 
                 lambda = 0, max_itr = 500)
# mixed
out_zip_mixed <- zip_mixed (claims = zip_sim$claims, X = zip_sim$X, years = zip_sim$years, locs = zip_sim$locs, agg_claims = zip_sim$agg_claims, 
                            A = zip_sim$A,  # can be NA in this case (is ignoted when A is learned)
                            exposure = zip_sim$exposure, model_type = "learn_graph", additive = TRUE, mixing = "ln",  
                            Emethod = "integration",
                            n_iter = 100, 
                            lambda = 0, 
                            optimizer_beta = "gd", optimizer_psi = "gd",
                            optimizer_a = "gd", optimizer_pi = "gd", optimizer_beta_phi = "gd",  # use gradient descent for each parameter
                            sgd = FALSE,  # can allow stochastic gradient but EM not guaranteed to take the correct step
                            batch_size = 100, # only used if sgd is true
                            verbose = 0, 
                            do_optim = FALSE,   # generally slower
                            calc_se = TRUE,
                            beta2_start = 0,   # takes some time
                            control_list = list(a = list(lr = 0.001),  # set learning rate, too high can lead to a decrease in lkelihood
                                                  beta_phi  = list(lr = 0.0001)),
                            max_itr_poisson = 500  # max number of iterations to start Poisson
                            )
```

    ## 
    ## Starting EM updates:
    ## [1] "Breaking because log-likelihood has stopped changing"

``` r
# Louis method error
sqrt(diag(solve(out_zip_mixed$Hessian-out_zip_mixed$var_loglik)))[1:5]
```

    ##                                 X11         X12         X13 
    ## 0.044667292 0.009032701 0.221433961 0.618717206 0.600556352

``` r
# Beta error
cat("\n# Beta Error\n")
```

    ## 
    ## # Beta Error

``` r
cat("Poisson model beta1 error:", sum(abs(out_zip$beta1 - zip_sim$beta1)), "\n")
```

    ## Poisson model beta1 error: 0.7673272

``` r
cat("Poisson mixed model beta1 error:", sum(abs(out_zip_mixed$beta1 - zip_sim$beta1)), "\n")
```

    ## Poisson mixed model beta1 error: 0.6042119

``` r
# Alpha error
cat("\n# Alpha Error\n")
```

    ## 
    ## # Alpha Error

``` r
cat("Poisson model a error:", sum(abs(out_zip$a - zip_sim$a)), "\n")
```

    ## Poisson model a error: 17.95661

``` r
cat("Poisson mixed model a error:", sum(abs(out_zip_mixed$a - zip_sim$a)), "\n")
```

    ## Poisson mixed model a error: 16.76104

``` r
# Beta_phi error
cat("\n# Beta_phi Error\n")
```

    ## 
    ## # Beta_phi Error

``` r
cat("Poisson mixed model beta2 error:", sum(abs(out_zip_mixed$beta2 - zip_sim$beta2)), "\n")
```

    ## Poisson mixed model beta2 error: 0.121224

``` r
#####################
# Test Zip psi
#####################

# We can also fit a model where A is known
zip_sim_psi <- simulate_claims(50, 100, spatial_type = "psi", additive =  TRUE, area = 10, 
                           model_type = "zip", mixing = "ln", density = 0.4,  seed = 1)

# not mixed
out_zip_psi <- zip(claims = zip_sim_psi$claims, X1 = zip_sim_psi$X, locs = zip_sim_psi$locs, 
               years = zip_sim_psi$years,  agg_claims = zip_sim_psi$agg_claims, 
                 A = zip_sim_psi$A, additive = TRUE, 
                model_type = "learn_psi", 
               exposure = zip_sim_psi$exposure, 
                 lambda = 0, max_itr = 500)
# mixed
out_zip_psi_mixed <- zip_mixed (claims = zip_sim_psi$claims, X = zip_sim_psi$X, years = zip_sim_psi$years, 
                                locs = zip_sim_psi$locs, 
                                agg_claims = zip_sim_psi$agg_claims, 
                                A = zip_sim_psi$A,   # has to be given when psi is learned
                                exposure = zip_sim_psi$exposure, model_type = "learn_psi", additive = TRUE, mixing = "ln",  
                                Emethod = "integration",
                                n_iter = 30, 
                                lambda = 0, # not used when psi is learned
                                verbose = 0, # set to 2 for convergence info
                                do_optim = FALSE,   # generally slower to use the L_BFGS within the EM.
                                calc_se = TRUE,
                                beta2_start = 0.1,   
                                control_list = list(psi = list(lr = 0.0001),  # set learning rate, too high can lead to a decrease in likelihood
                                                      beta_phi  = list(lr = 0.00001),
                                                    beta = list(lr = 0.0001),
                                                    pi = list(lr = 0.00001)),
                                max_itr_poisson = 100  # max number of iterations to start Poisson
                            )
```

    ## 
    ## Starting EM updates:

``` r
# Louis method error
sqrt(diag(solve(out_zip_psi_mixed$Hessian-out_zip_psi_mixed$var_loglik)))
```

    ##                              X11        X12        X13                                                                                                               
    ## 0.04225049 0.00898712 0.22837113 0.69710626 0.69823973 0.65033708 1.20946297 0.83040650 0.69251232 0.96627441 0.33314975 0.57568987 0.89359822 0.48720342 0.39350259

``` r
# Beta error
cat("\n# Beta Error\n")
```

    ## 
    ## # Beta Error

``` r
cat("ZIP psi model beta1 error:", sum(abs(out_zip_psi$beta1 - zip_sim_psi$beta1)), "\n")
```

    ## ZIP psi model beta1 error: 1.508419

``` r
cat("ZIP psi mixed model beta1 error:", sum(abs(out_zip_psi_mixed$beta1 - zip_sim_psi$beta1)), "\n")
```

    ## ZIP psi mixed model beta1 error: 1.407495

``` r
# Alpha error
cat("\n# Alpha Error\n")
```

    ## 
    ## # Alpha Error

``` r
cat("ZIP psi model a error:", sum(abs(out_zip_psi$psi - zip_sim_psi$psi)), "\n")
```

    ## ZIP psi model a error: 5.169256

``` r
cat("ZIP psi mixed model a error:", sum(abs(out_zip_psi_mixed$psi - zip_sim_psi$psi)), "\n")
```

    ## ZIP psi mixed model a error: 5.167184

``` r
# Beta_phi error
cat("\n# Beta_phi Error\n")
```

    ## 
    ## # Beta_phi Error

``` r
cat("ZIP psi mixed model beta2 error:", sum(abs(out_zip_psi_mixed$beta2 - zip_sim_psi$beta2)), "\n")
```

    ## ZIP psi mixed model beta2 error: 0.07877959

``` r
#####################
# Test Zip psi
#####################

# Test mixed hurdle
source("hurdle_mixed.R")  # Zip and mixed zip models
hurdle_sim <- simulate_claims(50, 100, spatial_type = "graph", additive =  TRUE, area = 10, 
                           model_type = "hurdle", mixing = "ig", density = 0.4,  seed = 1)

out_hurdle <- hurdle(hurdle_sim$claims, hurdle_sim$X, hurdle_sim$locs, hurdle_sim$years,  hurdle_sim$agg_claims, 
                 hurdle_sim$A, TRUE, "learn_graph", lambda = 0, exposure = hurdle_sim$exposure, max_itr = 500)

out_hurdle_mixed <- hurdle_mixed (claims = hurdle_sim$claims, X = hurdle_sim$X, years = hurdle_sim$years, locs = hurdle_sim$locs, agg_claims = hurdle_sim$agg_claims, 
                            A = hurdle_sim$A, exposure = hurdle_sim$exposure, model_type = "learn_graph", additive = TRUE, mixing = "ig",  
                            Emethod = "integration",
                            n_iter = 60, 
                            lambda = 0, 
                            optimizer_beta = "gd", optimizer_psi = "gd",
                            optimizer_a = "gd", optimizer_pi = "gd", optimizer_beta_phi = "gd",  # use gradient descent for each parameter
                            sgd = FALSE,  # can allow stochastic gradient but EM not guaranteed to take the correct step
                            batch_size = 100, 
                            verbose = 2, 
                            do_optim = FALSE,   # generally slower
                            calc_se = TRUE,
                            beta2_start = 0.2,   # takes some time
                            control_list = list(psi = list(a = 0.000001),  # set learning rate, too high can lead to a decrease in likelihood
                                                  beta_phi  = list(lr = 0.0001),
                                                beta = list(lr = 0.1)),
                            max_itr_poisson = 100  # number of iterations to start Poisson
                            )
```

    ## [1] "initial parameters:"
    ##    X1_tmp1    X1_tmp2    X1_tmp3 
    ##  1.3425653 -0.5461794  0.4990538 
    ## [1] 0.3964
    ## 
    ## Starting EM updates:
    ## [1] "log-likelihood value  -Inf"
    ## Iteration 1: beta = [1.3385, -0.5467, 0.5004], a = [0, 0, 0, 0, 0, 0.0446, 0.0152, 0.081, 0.0342, 0.0992, 0, 0, 0, 0.0034, 0.0773, 0, 0, 0, 0, 0, 0.052, 0, 0, 0, 0, 0, 0.0222, 0.0478, 0.0438, 0, 0.0501, 0, 0, 0.0263, 0.0608, 0.0879, 0, 0, 0, 0.0694, 0, 0.1543, 0, 0.0098, 0.1108, 0, 0, 0, 0, 0, 0.05, 0.0906, 0, 0, 0.1539], beta_phi = 0.212713, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9292.44170293861"
    ## Iteration 2: beta = [1.3329, -0.5474, 0.5021], a = [0, 0, 0, 0, 0, 0.0816, 0.0189, 0.1443, 0.0526, 0.1794, 0, 0, 0, 0, 0.1405, 0, 0, 0, 0, 0, 0.085, 0, 0, 0, 0, 0, 0.0179, 0.0783, 0.0733, 0, 0.0853, 0, 0, 0.0247, 0.0943, 0.1594, 0, 0, 0, 0.0975, 0, 0.2359, 0, 0, 0.1814, 0, 0, 0, 0, 0, 0.0531, 0.1251, 0, 0, 0.2542], beta_phi = 0.224386, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9285.96593660841"
    ## Iteration 3: beta = [1.3266, -0.5481, 0.5041], a = [0, 0, 0, 0, 0, 0.1154, 0.0179, 0.1996, 0.0632, 0.2513, 0, 0, 0, 0, 0.1974, 0, 0, 0, 0, 0, 0.1128, 0, 0, 0, 0, 0, 0.0083, 0.1029, 0.0969, 0, 0.114, 0, 0, 0.0156, 0.118, 0.2242, 0, 0, 0, 0.1091, 0, 0.2916, 0, 0, 0.236, 0, 0, 0, 0, 0, 0.0455, 0.1401, 0, 0, 0.3331], beta_phi = 0.235282, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9280.13240852394"
    ## Iteration 4: beta = [1.32, -0.5489, 0.5062], a = [0, 0, 0, 0, 0, 0.147, 0.0145, 0.2491, 0.0689, 0.3173, 0, 0, 0, 0, 0.2491, 0, 0, 0, 0, 0, 0.1388, 0, 0, 0, 0, 0, 0, 0.125, 0.1164, 0, 0.1382, 0, 0, 0.0043, 0.1367, 0.2838, 0, 0, 0, 0.1117, 0, 0.3326, 0, 0, 0.2804, 0, 0, 0, 0, 0, 0.0371, 0.1462, 0, 0, 0.3987], beta_phi = 0.245557, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9274.73860800935"
    ## Iteration 5: beta = [1.3133, -0.5497, 0.5083], a = [0, 0, 0, 0, 0, 0.1769, 0.0099, 0.2943, 0.0715, 0.3787, 0, 0, 0, 0, 0.2965, 0, 0, 0, 0, 0, 0.1641, 0, 0, 0, 0, 0, 0, 0.1456, 0.1333, 0, 0.1592, 0, 0, 0, 0.1527, 0.3394, 0, 0, 0, 0.1095, 0, 0.3651, 0, 0, 0.3182, 0, 0, 0, 0, 0, 0.0311, 0.1484, 0, 0, 0.4551], beta_phi = 0.255315, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9269.67700030981"
    ## Iteration 6: beta = [1.3064, -0.5504, 0.5104], a = [0, 0, 0, 0, 0, 0.2056, 0.0052, 0.336, 0.0721, 0.4365, 0, 0, 0, 0, 0.3404, 0, 0, 0, 0, 0, 0.1883, 0, 0, 0, 0, 0, 0, 0.1652, 0.148, 0, 0.1778, 0, 0, 0, 0.1665, 0.3914, 0, 0, 0, 0.105, 0, 0.3914, 0, 0, 0.3514, 0, 0, 0, 0, 0, 0.0273, 0.1487, 0, 0, 0.5047], beta_phi = 0.264608, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9264.88905898297"
    ## Iteration 7: beta = [1.2995, -0.5512, 0.5126], a = [0, 0, 0, 0, 0, 0.2333, 7e-04, 0.3749, 0.0714, 0.4912, 0, 0, 0, 0, 0.3814, 0, 0, 0, 0, 0, 0.2114, 0, 0, 0, 0, 0, 0, 0.1841, 0.1609, 0, 0.1946, 0, 0, 0, 0.1789, 0.4402, 0, 0, 0, 0.0997, 0, 0.4136, 0, 0, 0.3813, 0, 0, 0, 0, 0, 0.026, 0.1486, 0, 0, 0.5489], beta_phi = 0.273485, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9260.34297939285"
    ## Iteration 8: beta = [1.2926, -0.552, 0.5148], a = [0, 0, 0, 0, 0, 0.2601, 0, 0.4115, 0.0701, 0.5433, 0, 0, 0, 0, 0.4198, 0, 0, 0, 0, 0, 0.2336, 0, 0, 0, 0, 0, 0, 0.2026, 0.1726, 0, 0.2101, 0, 0, 0, 0.1905, 0.4861, 0, 0, 0, 0.0945, 0, 0.4329, 0, 0, 0.4088, 0, 0, 0, 0, 0, 0.0272, 0.1487, 0, 0, 0.5886], beta_phi = 0.281981, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9256.01475953471"
    ## Iteration 9: beta = [1.2858, -0.5528, 0.5169], a = [0, 0, 0, 0, 0, 0.2861, 0, 0.4458, 0.0684, 0.5928, 0, 0, 0, 0, 0.456, 0, 0, 0, 0, 0, 0.2549, 0, 0, 0, 0, 0, 0, 0.2207, 0.1833, 0, 0.2245, 0, 0, 0, 0.2015, 0.5294, 0, 0, 0, 0.0899, 0, 0.4502, 0, 0, 0.4343, 0, 0, 0, 0, 0, 0.0306, 0.1494, 0, 0, 0.6247], beta_phi = 0.290120, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9251.88697744315"
    ## Iteration 10: beta = [1.279, -0.5536, 0.5191], a = [0, 0, 0, 0, 0, 0.3115, 0, 0.4783, 0.0665, 0.6401, 0, 0, 0, 0, 0.4903, 0, 0, 0, 0, 0, 0.2754, 0, 0, 0, 0, 0, 0.0012, 0.2385, 0.1933, 0, 0.2382, 0, 0, 0, 0.2122, 0.5705, 0, 0, 0, 0.0862, 0, 0.466, 0, 0, 0.4582, 0, 0, 0, 0, 0, 0.0359, 0.1509, 0, 0, 0.6575], beta_phi = 0.297922, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9247.94552917997"
    ## Iteration 11: beta = [1.2722, -0.5544, 0.5212], a = [0, 0, 0, 0, 0, 0.3364, 0, 0.509, 0.0648, 0.6852, 0, 0, 0, 0, 0.5228, 0, 0, 0, 0, 0, 0.2951, 0, 0, 0, 0, 0, 0.0039, 0.2558, 0.2028, 0, 0.2513, 0, 0, 0, 0.2226, 0.6096, 0, 0, 0, 0.0836, 0, 0.4806, 0, 0, 0.4809, 0, 0, 0, 0, 0, 0.0426, 0.153, 0, 0, 0.6875], beta_phi = 0.305405, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9244.1789643611"
    ## Iteration 12: beta = [1.2655, -0.5552, 0.5233], a = [0, 0, 0, 0, 0, 0.3606, 0, 0.5382, 0.0632, 0.7283, 0, 0, 0, 0, 0.5539, 0, 0, 0, 0, 0, 0.3139, 0, 0, 0, 0, 0, 0.0079, 0.2726, 0.2119, 0, 0.2639, 0, 0, 0, 0.2326, 0.6467, 0, 0, 0, 0.082, 0, 0.4942, 0, 0, 0.5024, 0, 0, 0, 0, 0, 0.0503, 0.1558, 0, 0, 0.7151], beta_phi = 0.312580, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9240.57767816002"
    ## Iteration 13: beta = [1.2589, -0.556, 0.5254], a = [3e-04, 0, 0, 0, 0, 0.3844, 0, 0.566, 0.0619, 0.7696, 0, 0, 0, 0, 0.5836, 0, 0, 0, 0, 0, 0.3318, 0, 0, 0, 0, 0, 0.0126, 0.2889, 0.2209, 0, 0.2762, 0, 0, 0, 0.2423, 0.6821, 0, 0, 0, 0.0815, 0, 0.507, 0, 0, 0.5229, 0, 0, 0, 0, 0, 0.0587, 0.1591, 0, 0, 0.7406], beta_phi = 0.319462, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9237.13292735314"
    ## Iteration 14: beta = [1.2524, -0.5567, 0.5274], a = [0.0019, 0, 0, 0, 0, 0.4076, 5e-04, 0.5925, 0.0611, 0.8091, 0, 0, 0, 0, 0.6121, 0, 0, 0, 0, 0, 0.3489, 0, 0, 0, 0, 0, 0.018, 0.3047, 0.2297, 0, 0.2882, 0, 0, 0, 0.2516, 0.7159, 0, 0, 0, 0.082, 0, 0.519, 0, 0, 0.5425, 0, 0, 0, 0, 0, 0.0676, 0.1629, 0, 0, 0.7642], beta_phi = 0.326062, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9233.83651372021"
    ## Iteration 15: beta = [1.246, -0.5575, 0.5294], a = [0.0045, 0, 0, 0, 0, 0.4302, 0.002, 0.6178, 0.0606, 0.847, 0, 0, 0, 0, 0.6394, 0, 0, 0, 0, 0, 0.3652, 0, 0, 0, 0, 0, 0.0238, 0.3198, 0.2383, 0, 0.2999, 0, 0, 0, 0.2606, 0.7482, 0, 0, 0, 0.0835, 0, 0.5304, 0, 0, 0.5613, 0, 0, 0, 0, 0, 0.0768, 0.1671, 0, 0, 0.7862], beta_phi = 0.332392, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9230.68094005199"
    ## Iteration 16: beta = [1.2396, -0.5582, 0.5314], a = [0.0082, 0, 4e-04, 0, 0, 0.4524, 0.0043, 0.6419, 0.0605, 0.8832, 0, 0, 0, 0, 0.6658, 0, 0, 0, 0, 0, 0.3808, 0, 0, 0, 0, 0, 0.0299, 0.3344, 0.2469, 0, 0.3114, 0, 0, 0, 0.2694, 0.779, 0, 0, 0, 0.0858, 0, 0.5414, 0, 0, 0.5793, 0, 0, 0, 0, 0, 0.0863, 0.1718, 0, 0, 0.8068], beta_phi = 0.338462, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9227.65929418883"
    ## Iteration 17: beta = [1.2334, -0.559, 0.5334], a = [0.0128, 0, 0.0013, 0, 0, 0.474, 0.0074, 0.6649, 0.0607, 0.9178, 0, 0, 0, 0, 0.6912, 0, 0, 0, 0, 0, 0.3956, 0, 0, 0, 0, 0, 0.0362, 0.3483, 0.2553, 0, 0.3227, 0, 0, 0, 0.2778, 0.8085, 0, 0, 0, 0.0888, 0, 0.5518, 0, 0, 0.5966, 0, 0, 0, 0, 0, 0.096, 0.1767, 0, 0, 0.826], beta_phi = 0.344282, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9224.76520183058"
    ## Iteration 18: beta = [1.2272, -0.5597, 0.5354], a = [0.0181, 0, 0.0029, 0, 0, 0.4951, 0.0111, 0.687, 0.0614, 0.951, 0, 0, 0, 0, 0.7158, 0, 0, 0, 0, 0, 0.4098, 0, 0, 0, 0, 0, 0.0427, 0.3618, 0.2636, 0, 0.3338, 0, 0, 0, 0.286, 0.8367, 0, 0, 0, 0.0925, 0, 0.5619, 0, 0, 0.6132, 0, 0, 0, 0, 0, 0.1058, 0.182, 0, 0, 0.8442], beta_phi = 0.349863, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9221.99275647181"
    ## Iteration 19: beta = [1.2211, -0.5604, 0.5373], a = [0.0242, 0, 0.005, 0, 0, 0.5157, 0.0154, 0.708, 0.0624, 0.9826, 0, 0, 0, 0, 0.7395, 0, 0, 0, 0, 0, 0.4233, 0, 0, 0, 0, 0, 0.0493, 0.3746, 0.2716, 0, 0.3448, 0, 0, 0, 0.294, 0.8637, 0, 0, 0, 0.0967, 0, 0.5717, 0, 0, 0.6291, 0, 0, 0, 0, 0, 0.1156, 0.1876, 0, 0, 0.8614], beta_phi = 0.355213, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9219.33645173482"
    ## Iteration 20: beta = [1.2152, -0.5611, 0.5392], a = [0.0309, 0, 0.0076, 0, 0, 0.5358, 0.0201, 0.7281, 0.0637, 1.0128, 0, 0, 0, 0, 0.7626, 0, 0, 0, 0, 0, 0.4363, 0, 0, 0, 0, 0, 0.0559, 0.3869, 0.2795, 0, 0.3556, 0, 0, 0, 0.3018, 0.8897, 0, 0, 0, 0.1013, 0, 0.5811, 0, 0, 0.6445, 0, 0, 0, 0, 0, 0.1254, 0.1933, 0, 0, 0.8776], beta_phi = 0.360342, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9216.79112737399"
    ## Iteration 21: beta = [1.2093, -0.5619, 0.541], a = [0.0381, 0, 0.0107, 0, 0, 0.5554, 0.0253, 0.7473, 0.0653, 1.0417, 0, 0, 0, 0, 0.7849, 0, 0, 0, 0, 0, 0.4488, 0, 0, 0, 0, 0, 0.0625, 0.3988, 0.2872, 0, 0.3663, 0, 0, 0, 0.3093, 0.9145, 0, 0, 0, 0.1063, 0, 0.5903, 0, 0, 0.6594, 0, 0, 0, 0, 0, 0.1352, 0.1993, 0, 0, 0.8931], beta_phi = 0.365258, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9214.35192860773"
    ## Iteration 22: beta = [1.2035, -0.5625, 0.5429], a = [0.0458, 0, 0.0144, 0, 0, 0.5745, 0.0308, 0.7657, 0.0672, 1.0693, 0, 0, 0, 0, 0.8066, 0, 0, 0, 0, 0, 0.4607, 0, 0, 0, 0, 0, 0.0692, 0.4101, 0.2947, 0, 0.3768, 0, 0, 0, 0.3167, 0.9384, 0, 0, 0, 0.1116, 0, 0.5993, 0, 0, 0.6736, 0, 0, 0, 0, 0, 0.1449, 0.2054, 0, 0, 0.9079], beta_phi = 0.369969, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9212.01426388125"
    ## Iteration 23: beta = [1.1978, -0.5632, 0.5447], a = [0.0539, 0, 0.0185, 0, 0, 0.593, 0.0365, 0.7834, 0.0693, 1.0956, 0, 0, 0, 0, 0.8276, 0, 0, 0, 0, 0, 0.4722, 0, 0, 0, 0, 0, 0.0758, 0.4209, 0.3021, 0, 0.3871, 0, 0, 0, 0.324, 0.9614, 0, 0, 0, 0.1172, 0, 0.608, 0, 0, 0.6874, 0, 0, 0, 0, 0, 0.1545, 0.2116, 0, 0, 0.922], beta_phi = 0.374485, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9209.77378912223"
    ## Iteration 24: beta = [1.1922, -0.5639, 0.5465], a = [0.0624, 0, 0.0231, 0, 0, 0.6111, 0.0425, 0.8002, 0.0717, 1.1207, 0, 0, 0, 0, 0.8481, 0, 0, 0, 0, 0, 0.4832, 0, 0, 0, 0, 0, 0.0824, 0.4313, 0.3092, 0, 0.3974, 0, 0, 0, 0.331, 0.9834, 0, 0, 0, 0.123, 0, 0.6165, 0, 0, 0.7007, 0, 0, 0, 0, 0, 0.1641, 0.2179, 0, 0, 0.9355], beta_phi = 0.378812, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9207.62622102905"
    ## Iteration 25: beta = [1.1868, -0.5646, 0.5482], a = [0.0711, 0, 0.0281, 0, 0, 0.6286, 0.0487, 0.8164, 0.0744, 1.1446, 0, 0, 0, 0, 0.868, 0, 0, 0, 0, 0, 0.4939, 0, 0, 0, 0, 0, 0.0889, 0.4413, 0.3161, 0, 0.4074, 0, 0, 0, 0.338, 1.0046, 0, 0, 0, 0.1289, 0, 0.6248, 0, 0, 0.7136, 0, 0, 0, 0, 0, 0.1735, 0.2242, 0, 0, 0.9484], beta_phi = 0.382959, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9205.56808484245"
    ## Iteration 26: beta = [1.1814, -0.5652, 0.5499], a = [0.0801, 0, 0.0336, 0, 0, 0.6457, 0.055, 0.8318, 0.0772, 1.1675, 0, 0, 0, 0, 0.8874, 0, 0, 0, 0, 0, 0.5041, 0, 0, 0, 0, 0, 0.0954, 0.4508, 0.3228, 0, 0.4173, 0, 0, 0, 0.3447, 1.025, 0, 0, 0, 0.135, 0, 0.6329, 0, 0, 0.726, 0, 0, 0, 0, 0, 0.1827, 0.2306, 0, 0, 0.9609], beta_phi = 0.386931, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9203.59518140622"
    ## Iteration 27: beta = [1.1761, -0.5659, 0.5516], a = [0.0892, 0, 0.0394, 0, 0, 0.6623, 0.0615, 0.8467, 0.0802, 1.1893, 0, 0, 0, 0, 0.9063, 0, 0, 0, 0, 0, 0.5141, 0, 0, 0, 0, 0, 0.1018, 0.46, 0.3293, 0, 0.4271, 0, 0, 0, 0.3514, 1.0447, 0, 0, 0, 0.1412, 0, 0.6409, 0, 0, 0.7381, 0, 0, 0, 0, 0, 0.1919, 0.237, 0, 0, 0.9729], beta_phi = 0.390737, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9201.70408236696"
    ## Iteration 28: beta = [1.1709, -0.5665, 0.5533], a = [0.0985, 0, 0.0455, 0, 0, 0.6784, 0.068, 0.8609, 0.0834, 1.2101, 0, 0, 0, 0, 0.9246, 0, 0, 0, 0, 0, 0.5236, 0, 0, 0, 0, 0, 0.1081, 0.4688, 0.3357, 0, 0.4367, 0, 0, 0, 0.3579, 1.0636, 0, 0, 0, 0.1474, 0, 0.6487, 0, 0, 0.7497, 0, 0, 0, 0, 0, 0.2008, 0.2434, 0, 0, 0.9845], beta_phi = 0.394382, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9199.89136707632"
    ## Iteration 29: beta = [1.1657, -0.5672, 0.5549], a = [0.1079, 0, 0.052, 0, 0, 0.6941, 0.0746, 0.8746, 0.0868, 1.2299, 0, 0, 0, 0, 0.9425, 0, 0, 0, 0, 0, 0.5329, 0, 0, 0, 0, 0, 0.1144, 0.4772, 0.3418, 0, 0.4462, 0, 0, 0, 0.3643, 1.0818, 0, 0, 0, 0.1537, 0, 0.6563, 0, 0, 0.761, 0, 0, 0, 0, 0, 0.2097, 0.2498, 0, 0, 0.9957], beta_phi = 0.397874, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9198.15376612492"
    ## Iteration 30: beta = [1.1607, -0.5678, 0.5565], a = [0.1174, 0, 0.0588, 0, 0, 0.7093, 0.0812, 0.8877, 0.0903, 1.2489, 0, 0, 0, 0, 0.96, 0, 0, 0, 0, 0, 0.5419, 0, 0, 0, 0, 0, 0.1205, 0.4853, 0.3478, 0, 0.4554, 0, 0, 0, 0.3706, 1.0994, 0, 0, 0, 0.1601, 0, 0.6638, 0, 0, 0.7719, 0, 0, 0, 0, 0, 0.2183, 0.2562, 0, 0, 1.0066], beta_phi = 0.401217, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9196.48814858959"
    ## Iteration 31: beta = [1.1558, -0.5684, 0.5581], a = [0.1269, 0, 0.0658, 0, 0, 0.724, 0.0878, 0.9003, 0.0939, 1.2669, 0, 0, 0, 0, 0.9769, 0, 0, 0, 0, 0, 0.5506, 0, 0, 0, 0, 0, 0.1266, 0.4931, 0.3536, 0, 0.4646, 0, 0, 0, 0.3768, 1.1164, 0, 0, 0, 0.1664, 0, 0.6711, 0, 0, 0.7825, 0, 0, 0, 0, 0, 0.2269, 0.2625, 0, 0, 1.0171], beta_phi = 0.404419, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9194.8915165787"
    ## Iteration 32: beta = [1.151, -0.569, 0.5597], a = [0.1364, 0, 0.0731, 0, 0, 0.7383, 0.0945, 0.9124, 0.0976, 1.2841, 0, 0, 0, 0, 0.9935, 0, 0, 0, 0, 0, 0.5591, 0, 0, 0, 0, 0, 0.1325, 0.5006, 0.3592, 0, 0.4735, 0, 0, 0, 0.3828, 1.1327, 0, 0, 0, 0.1727, 0, 0.6783, 0, 0, 0.7928, 0, 0, 0, 0, 0, 0.2352, 0.2687, 0, 0, 1.0273], beta_phi = 0.407485, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9193.3606704865"
    ## Iteration 33: beta = [1.1462, -0.5696, 0.5612], a = [0.1459, 0, 0.0807, 0, 0, 0.7522, 0.1011, 0.9241, 0.1014, 1.3005, 0, 0, 0, 0.0013, 1.0097, 0, 0, 0, 0, 0, 0.5673, 0, 0, 0, 0, 0, 0.1384, 0.5079, 0.3647, 0, 0.4823, 0, 0, 0, 0.3888, 1.1485, 0, 0, 0, 0.179, 0, 0.6853, 0, 0, 0.8028, 0, 0, 0, 0, 0, 0.2434, 0.2749, 0, 0, 1.0372], beta_phi = 0.410420, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9191.8923363746"
    ## Iteration 34: beta = [1.1416, -0.5702, 0.5627], a = [0.1554, 0, 0.0884, 0, 0, 0.7657, 0.1076, 0.9353, 0.1053, 1.3161, 0, 0, 0, 0.0036, 1.0253, 0, 0, 0, 0, 0, 0.5752, 0, 0, 0, 0, 0, 0.1442, 0.5148, 0.37, 0, 0.491, 0, 0, 0, 0.3946, 1.1638, 0, 0, 0, 0.1852, 0, 0.6922, 0, 0, 0.8125, 0, 0, 0, 0, 0, 0.2514, 0.281, 0, 0, 1.0469], beta_phi = 0.413229, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9190.48358214256"
    ## Iteration 35: beta = [1.137, -0.5708, 0.5642], a = [0.1649, 0, 0.0964, 0, 0, 0.7787, 0.1141, 0.946, 0.1092, 1.331, 0, 0, 0, 0.0068, 1.0405, 0, 0, 0, 0, 0, 0.583, 0, 0, 0, 0, 0, 0.1499, 0.5215, 0.3752, 0, 0.4994, 0, 0, 0, 0.4003, 1.1786, 0, 0, 0, 0.1912, 0, 0.699, 0, 0, 0.8219, 0, 0, 0, 0, 0, 0.2593, 0.287, 0, 0, 1.0562], beta_phi = 0.415916, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9189.1317238"
    ## Iteration 36: beta = [1.1325, -0.5713, 0.5656], a = [0.1742, 0, 0.1044, 0, 0, 0.7914, 0.1204, 0.9563, 0.113, 1.3451, 0, 0, 0, 0.0105, 1.0552, 0, 0, 0, 0, 0, 0.5905, 0, 0, 0, 0, 0, 0.1555, 0.528, 0.3803, 0, 0.5078, 0, 0, 0, 0.4059, 1.1928, 0, 0, 0, 0.1971, 0, 0.7056, 0, 0, 0.831, 0, 0, 0, 0, 0, 0.267, 0.293, 0, 0, 1.0653], beta_phi = 0.418488, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9187.83426327949"
    ## Iteration 37: beta = [1.1281, -0.5719, 0.5671], a = [0.1835, 0, 0.1127, 0, 0, 0.8037, 0.1266, 0.9661, 0.1169, 1.3585, 0, 0, 0, 0.0146, 1.0694, 0, 0, 0, 0, 0, 0.5979, 0, 0, 0, 0, 0, 0.1609, 0.5342, 0.3852, 0, 0.5159, 0, 0, 0, 0.4115, 1.2066, 0, 0, 0, 0.2029, 0, 0.7121, 0, 0, 0.8399, 0, 0, 0, 0, 0, 0.2746, 0.2989, 0, 0, 1.0742], beta_phi = 0.420947, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9186.58872920065"
    ## Iteration 38: beta = [1.1238, -0.5725, 0.5685], a = [0.1928, 0, 0.121, 0, 0, 0.8156, 0.1327, 0.9755, 0.1207, 1.3712, 0, 0, 0, 0.019, 1.0832, 0, 0, 0, 0, 0, 0.605, 0, 0, 0, 0, 6e-04, 0.1663, 0.5403, 0.39, 0, 0.5239, 0, 0, 0, 0.4169, 1.2199, 0, 0, 0, 0.2084, 0, 0.7185, 0, 0, 0.8486, 0, 0, 0, 0, 0, 0.282, 0.3047, 0, 0, 1.0829], beta_phi = 0.423300, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9185.39219194469"
    ## Iteration 39: beta = [1.1195, -0.573, 0.5699], a = [0.2019, 0, 0.1295, 0, 0, 0.8272, 0.1386, 0.9845, 0.1245, 1.3833, 0, 0, 0, 0.0237, 1.0964, 0, 0, 0, 0, 0, 0.612, 0, 0, 0, 0, 0.0027, 0.1716, 0.5461, 0.3947, 0, 0.5318, 0, 0, 0, 0.4222, 1.2329, 0, 0, 0, 0.2139, 0, 0.7248, 0, 0, 0.8571, 0, 0, 0, 0, 0, 0.2893, 0.3103, 0, 0, 1.0913], beta_phi = 0.425551, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9184.24197748858"
    ## Iteration 40: beta = [1.1154, -0.5736, 0.5712], a = [0.2109, 0, 0.138, 0, 0, 0.8385, 0.1445, 0.9932, 0.1283, 1.3947, 0, 0, 0, 0.0284, 1.1091, 0, 0, 0, 0, 0, 0.6187, 0, 0, 0, 0, 0.0059, 0.1767, 0.5516, 0.3993, 0, 0.5395, 0, 0, 0, 0.4272, 1.2454, 0, 0, 0, 0.2192, 0, 0.731, 0, 0, 0.8654, 0, 0, 0, 0, 0, 0.2964, 0.3158, 0, 0, 1.0995], beta_phi = 0.427703, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9183.13584329353"
    ## Iteration 41: beta = [1.1113, -0.5741, 0.5726], a = [0.2198, 0, 0.1467, 0, 0, 0.8494, 0.1502, 1.0015, 0.1321, 1.4056, 0, 0, 0, 0.0333, 1.1212, 0, 0, 0, 0, 0, 0.6254, 0, 0, 0, 0, 0.0098, 0.1815, 0.5569, 0.4038, 0, 0.5471, 0, 0, 0, 0.432, 1.2575, 0, 0, 0, 0.2244, 0, 0.7371, 0, 0, 0.8735, 0, 0, 0, 0, 0, 0.3034, 0.321, 0, 0, 1.1076], beta_phi = 0.429761, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9182.07179748974"
    ## Iteration 42: beta = [1.1072, -0.5746, 0.5739], a = [0.2286, 0, 0.1553, 0, 0, 0.86, 0.1558, 1.0095, 0.1359, 1.416, 0, 0, 0, 0.0381, 1.1328, 0, 0, 0, 0, 0, 0.6318, 0, 0, 0, 0, 0.0141, 0.1862, 0.5619, 0.4082, 0, 0.5546, 0, 0, 0, 0.4365, 1.2692, 0, 0, 0, 0.2295, 0, 0.7431, 0, 0, 0.8814, 0, 0, 0, 0, 0, 0.3103, 0.326, 0, 0, 1.1155], beta_phi = 0.431730, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9181.0480181957"
    ## Iteration 43: beta = [1.1033, -0.5751, 0.5752], a = [0.2373, 0, 0.1641, 0, 0, 0.8703, 0.1614, 1.0172, 0.1397, 1.4258, 0, 0, 0, 0.0429, 1.1438, 0, 0, 0, 0, 0, 0.6382, 0, 0, 0, 0, 0.0188, 0.1907, 0.5667, 0.4125, 0, 0.5619, 0, 0, 0, 0.4408, 1.2806, 0, 0, 0, 0.2345, 0, 0.749, 0, 0, 0.8892, 0, 0, 0, 0, 0, 0.317, 0.3308, 0, 0, 1.1232], beta_phi = 0.433613, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9180.06281135972"
    ## Iteration 44: beta = [1.0994, -0.5757, 0.5765], a = [0.2458, 0, 0.1728, 0, 0, 0.8803, 0.1668, 1.0246, 0.1434, 1.4351, 0, 0, 0, 0.0477, 1.1544, 0, 0, 0, 0, 0, 0.6443, 0, 0, 0, 0, 0.0237, 0.195, 0.5713, 0.4168, 0, 0.5691, 0, 0, 0, 0.4449, 1.2916, 0, 0, 0, 0.2394, 0, 0.7547, 0, 0, 0.8967, 0, 0, 0, 0, 0, 0.3237, 0.3355, 0, 0, 1.1308], beta_phi = 0.435415, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9179.11456324127"
    ## Iteration 45: beta = [1.0956, -0.5762, 0.5777], a = [0.2542, 0, 0.1816, 0, 0, 0.89, 0.1722, 1.0317, 0.1472, 1.4439, 0, 0, 0, 0.0525, 1.1644, 0, 0, 0, 0, 0, 0.6504, 0, 3e-04, 0, 0, 0.0287, 0.1993, 0.5757, 0.421, 0, 0.5761, 0, 0, 0, 0.4489, 1.3023, 0, 0, 0, 0.2443, 0, 0.7604, 0, 0, 0.9041, 0, 0, 0, 0, 0, 0.3303, 0.3401, 0, 0, 1.1382], beta_phi = 0.437139, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9178.20167091576"
    ## Iteration 46: beta = [1.0918, -0.5767, 0.579], a = [0.2625, 0, 0.1904, 0, 0, 0.8995, 0.1774, 1.0386, 0.1509, 1.4524, 0, 0, 0, 0.0573, 1.1741, 0, 0, 0, 0, 0, 0.6563, 0, 0.0011, 0, 0, 0.0338, 0.2034, 0.5799, 0.4251, 0, 0.5831, 0, 0, 0, 0.4526, 1.3128, 0, 0, 0, 0.249, 0, 0.766, 0, 0, 0.9113, 0, 0, 0, 0, 0, 0.3367, 0.3446, 0, 0, 1.1455], beta_phi = 0.438789, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9177.32262090058"
    ## Iteration 47: beta = [1.0881, -0.5772, 0.5802], a = [0.2706, 0, 0.1991, 0, 0, 0.9086, 0.1826, 1.0452, 0.1546, 1.4604, 0, 0, 0, 0.062, 1.1833, 0, 0, 0, 0, 0, 0.6621, 0, 0.0024, 0, 0, 0.0389, 0.2074, 0.5839, 0.4292, 0, 0.5899, 0, 0, 0, 0.4562, 1.3229, 0, 0, 0, 0.2537, 0, 0.7715, 0, 0, 0.9184, 0, 0, 0, 0, 0, 0.343, 0.3489, 0, 0, 1.1527], beta_phi = 0.440367, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9176.47586879507"
    ## Iteration 48: beta = [1.0845, -0.5777, 0.5814], a = [0.2786, 0, 0.2078, 0, 0, 0.9176, 0.1877, 1.0516, 0.1584, 1.468, 0, 0, 0, 0.0668, 1.1922, 0, 0, 0, 0, 0, 0.6678, 0, 0.004, 0, 0, 0.044, 0.2113, 0.5878, 0.4332, 0, 0.5966, 0, 0, 0, 0.4596, 1.3327, 0, 0, 0, 0.2583, 0, 0.7769, 0, 6e-04, 0.9253, 0, 0, 0, 0, 0, 0.3493, 0.3531, 0, 0, 1.1597], beta_phi = 0.441878, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9175.65949844239"
    ## Iteration 49: beta = [1.081, -0.5781, 0.5826], a = [0.2865, 0, 0.2164, 0, 0, 0.9262, 0.1928, 1.0578, 0.1621, 1.4752, 0, 0, 0, 0.0714, 1.2007, 0, 0, 0, 0, 0, 0.6733, 0, 0.0059, 0, 0, 0.049, 0.2151, 0.5915, 0.4371, 0, 0.6032, 0, 0, 0, 0.4628, 1.3422, 0, 0, 0, 0.2628, 0, 0.7821, 0, 0.0027, 0.9321, 0, 0, 0, 0, 0, 0.3554, 0.3572, 0, 0, 1.1666], beta_phi = 0.443323, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9174.8718519352"
    ## Iteration 50: beta = [1.0775, -0.5786, 0.5837], a = [0.2942, 0, 0.2249, 0, 0, 0.9347, 0.1977, 1.0638, 0.1657, 1.482, 0, 0, 0, 0.076, 1.2089, 0, 0, 0, 0, 0, 0.6788, 0, 0.008, 0, 0, 0.054, 0.2188, 0.595, 0.4409, 0, 0.6096, 0, 0, 0, 0.4658, 1.3515, 0, 0, 0, 0.2671, 0, 0.7871, 0, 0.0056, 0.9385, 0, 0, 0, 0, 0, 0.3614, 0.3613, 0, 0, 1.1733], beta_phi = 0.444707, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9174.11158800877"
    ## Iteration 51: beta = [1.074, -0.5791, 0.5849], a = [0.3018, 0, 0.2334, 0, 0, 0.9429, 0.2026, 1.0696, 0.1694, 1.4886, 0, 0, 0, 0.0806, 1.2168, 0, 0, 0, 0, 0, 0.6841, 0, 0.0103, 0, 0, 0.0588, 0.2224, 0.5984, 0.4446, 0, 0.6158, 0, 0, 0, 0.4686, 1.3604, 0, 0, 0, 0.2713, 0, 0.7917, 0, 0.009, 0.9447, 0, 0, 0, 0, 0, 0.3673, 0.3653, 0, 0, 1.18], beta_phi = 0.446032, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9173.37753491304"
    ## Iteration 52: beta = [1.0706, -0.5796, 0.586], a = [0.3092, 0, 0.2417, 0, 0, 0.9508, 0.2075, 1.0752, 0.1731, 1.4948, 0, 0, 0, 0.0852, 1.2244, 0, 0, 0, 0, 0, 0.6894, 0, 0.0128, 0, 0, 0.0637, 0.2259, 0.6016, 0.4482, 0, 0.6218, 0, 0, 0, 0.4712, 1.369, 0, 0, 0, 0.2753, 0, 0.7961, 0, 0.0129, 0.9507, 0, 0, 0, 0, 0, 0.3731, 0.3692, 0, 0, 1.1865], beta_phi = 0.447302, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9172.66862986341"
    ## Iteration 53: beta = [1.0673, -0.58, 0.5871], a = [0.3165, 0, 0.2499, 0, 0, 0.9586, 0.2122, 1.0807, 0.1767, 1.5007, 0, 0, 0, 0.0897, 1.2318, 0, 0, 0, 0, 0, 0.6946, 0, 0.0153, 0, 0, 0.0684, 0.2295, 0.6047, 0.4517, 0, 0.6277, 0, 0, 0, 0.4737, 1.3773, 0, 0, 0, 0.2793, 0, 0.8002, 0, 0.017, 0.9563, 0, 0, 0, 0, 0, 0.3788, 0.3731, 0, 0, 1.1929], beta_phi = 0.448518, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9171.98388906786"
    ## Iteration 54: beta = [1.064, -0.5805, 0.5882], a = [0.3237, 0, 0.258, 0, 0, 0.9662, 0.217, 1.086, 0.1803, 1.5063, 0, 0, 0, 0.0942, 1.2389, 0, 0, 0, 0, 0, 0.6996, 0, 0.018, 0, 0, 0.0731, 0.233, 0.6077, 0.4551, 0, 0.6334, 0, 0, 0, 0.476, 1.3854, 0, 0, 0, 0.2831, 0, 0.8041, 0, 0.0212, 0.9618, 0, 0, 0, 0, 0, 0.3845, 0.3769, 0, 0, 1.1991], beta_phi = 0.449684, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9171.32239078499"
    ## Iteration 55: beta = [1.0608, -0.5809, 0.5893], a = [0.3307, 0, 0.266, 0, 0, 0.9736, 0.2216, 1.0911, 0.1839, 1.5117, 0, 0, 0, 0.0986, 1.2459, 0, 0, 0, 0, 0, 0.7046, 0, 0.0207, 0, 0, 0.0777, 0.2364, 0.6106, 0.4584, 0, 0.6389, 0, 0, 0, 0.4782, 1.3931, 0, 0, 0, 0.2869, 0, 0.8078, 0, 0.0256, 0.9671, 0, 0, 0, 0, 0, 0.39, 0.3806, 0, 0, 1.2052], beta_phi = 0.450802, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9170.68326374064"
    ## Iteration 56: beta = [1.0576, -0.5814, 0.5903], a = [0.3377, 0, 0.2738, 0, 0, 0.9808, 0.2262, 1.0961, 0.1875, 1.5168, 0, 0, 0, 0.103, 1.2526, 0, 0, 0, 0, 0, 0.7096, 0, 0.0235, 0, 0, 0.0822, 0.2398, 0.6134, 0.4617, 0, 0.6442, 0, 0, 0, 0.4803, 1.4006, 0, 0, 0, 0.2906, 0, 0.8114, 0, 0.03, 0.9721, 0, 0, 0, 0, 0, 0.3955, 0.3844, 0, 0, 1.2113], beta_phi = 0.451875, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9170.06564352631"
    ## Iteration 57: beta = [1.0545, -0.5818, 0.5914], a = [0.3445, 0, 0.2815, 0, 0, 0.9878, 0.2307, 1.101, 0.1911, 1.5216, 0, 0, 0, 0.1074, 1.2591, 0, 0, 0, 0, 0, 0.7144, 0, 0.0263, 0, 0, 0.0867, 0.2432, 0.616, 0.4649, 0, 0.6495, 0, 0, 4e-04, 0.4823, 1.4079, 0, 0, 0, 0.2942, 0, 0.8148, 0, 0.0344, 0.977, 0, 0, 0, 0, 0, 0.4009, 0.388, 0, 0, 1.2172], beta_phi = 0.452904, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9169.46868869636"
    ## Iteration 58: beta = [1.0514, -0.5823, 0.5924], a = [0.3511, 0, 0.2891, 0, 0, 0.9946, 0.2352, 1.1057, 0.1947, 1.5262, 0, 0, 0, 0.1117, 1.2654, 0, 0, 0, 0, 0, 0.7192, 0, 0.0291, 0, 0, 0.0911, 0.2464, 0.6186, 0.468, 0, 0.6545, 0, 0, 0.0012, 0.4842, 1.4149, 0, 0, 0, 0.2978, 0, 0.8181, 0, 0.0388, 0.9818, 0, 0, 0, 0, 0, 0.4061, 0.3916, 0, 0, 1.2229], beta_phi = 0.453891, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9168.89161650477"
    ## Iteration 59: beta = [1.0484, -0.5827, 0.5934], a = [0.3577, 0, 0.2965, 0, 0, 1.0013, 0.2396, 1.1104, 0.1982, 1.5306, 0, 0, 0, 0.1159, 1.2716, 0, 0, 0, 0, 0, 0.7238, 0, 0.0319, 0, 0, 0.0954, 0.2497, 0.6211, 0.471, 0, 0.6595, 0, 0, 0.0022, 0.486, 1.4216, 0, 0, 0, 0.3013, 0, 0.8213, 0, 0.0432, 0.9864, 0, 0, 0, 0, 0, 0.4113, 0.3952, 0, 0, 1.2286], beta_phi = 0.454838, pi = 0.396400 
    ## ,[1] "log-likelihood value  -9168.33368915385"
    ## Iteration 60: beta = [1.0454, -0.5831, 0.5945], a = [0.3641, 0, 0.3038, 0, 0, 1.0078, 0.244, 1.1149, 0.2017, 1.5348, 0, 0, 0, 0.1201, 1.2776, 0, 0, 0, 0, 0, 0.7283, 0, 0.0348, 0, 0, 0.0997, 0.2528, 0.6235, 0.4739, 0, 0.6643, 0, 0, 0.0034, 0.4877, 1.4281, 0, 0, 0, 0.3048, 0, 0.8243, 0, 0.0476, 0.9909, 0, 0, 0, 0, 0, 0.4162, 0.3987, 0, 0, 1.2342], beta_phi = 0.455748, pi = 0.396400 
    ## ,

``` r
# Louis method error
sqrt(diag(solve(out_hurdle_mixed$Hessian-out_hurdle_mixed$var_loglik)))
```

    ##  [1] 0.035324002 0.006917616 0.083321152 0.210525661 0.216439823 0.385034740 0.314457633 0.453080092 0.282482777 0.300840852 0.373430404 0.260136547 0.335955687 0.252022840 0.438867254
    ## [16] 0.230791512 0.273930918 0.230516266 0.220619185 0.307084255 0.249308235 0.278034274 0.216316450 0.226107573 0.209408854 0.297494918 0.242038062 0.266155913 0.209338227 0.227558629
    ## [31] 0.205817652 0.201757531 0.294524289 0.292254035 0.295144655 0.270836425 0.257181385 0.243730941 0.232325060 0.237920296 0.461031081 0.208379145 0.234149597 0.211275572 0.211829054
    ## [46] 0.188326631 0.197240170 0.182833684 0.202275395 0.258191751 0.212393131 0.222832249 0.196819274 0.197431260 0.189613948 0.182510111 0.189404167 0.210957473 0.169324772 0.247166352

``` r
# Beta error
cat("\n# Beta Error\n")
```

    ## 
    ## # Beta Error

``` r
cat("Hurdle model beta1 error:", sum(abs(out_hurdle$beta1 - hurdle_sim$beta1)), "\n")
```

    ## Hurdle model beta1 error: 1.297332

``` r
cat("Hurdle mixed model beta1 error:", sum(abs(out_hurdle_mixed$beta1 - hurdle_sim$beta1)), "\n")
```

    ## Hurdle mixed model beta1 error: 0.8678489

``` r
# Alpha error
cat("\n# Alpha Error\n")
```

    ## 
    ## # Alpha Error

``` r
cat("Hurdle model a error:", sum(abs(out_hurdle$a - hurdle_sim$a)), "\n")
```

    ## Hurdle model a error: 20.84158

``` r
cat("Hurdle mixed model a error:", sum(abs(out_hurdle_mixed$a - hurdle_sim$a)), "\n")
```

    ## Hurdle mixed model a error: 8.036557

``` r
# Beta_phi error
cat("\n# Beta_phi Error\n")
```

    ## 
    ## # Beta_phi Error

``` r
cat("Hurdle mixed model beta2 error:", sum(abs(out_hurdle_mixed$beta2 - hurdle_sim$beta2)), "\n")
```

    ## Hurdle mixed model beta2 error: 0.04425221

The experiments in the paper were run by running `poisson_test.R`,
`zip_test.R`, `hurdle_test.R`, `speed_test.R` and `test_direct_vs_em.R`,
but they do take quite some time to run. To generate the plots, run
`visualize.R` which reads the data from the simulation experiments from
the folder `data_sim`.
